{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mediterranean-force",
   "metadata": {},
   "source": [
    "# journalists scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-forwarding",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# Reqeusts\n",
    "import requests\n",
    "# Other tools\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import fnmatch\n",
    "import os\n",
    "import tabula\n",
    "from tabula.io import read_pdf\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-trade",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def requests_get_item(url, item):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"}\n",
    "    if item == \"html\":       \n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        return(soup)\n",
    "    \n",
    "    elif item == \"pdf\":\n",
    "        page = requests.get(url, headers = headers, stream=True)\n",
    "        return(page)\n",
    "    else:\n",
    "        print(\"Valid Item Not Selected\")\n",
    "\n",
    "def download_pdfs(ls_pdf_urls, download_path, file_name):\n",
    "    counter = 0 \n",
    "    for pdf_url in ls_pdf_urls:\n",
    "        counter = counter +1\n",
    "        g = requests_get_item(pdf_url, \"pdf\")\n",
    "        with open(f'{download_path}{file_name}_{counter}.pdf', 'wb') as sav:\n",
    "            for chunk in g.iter_content(chunk_size=1000000):\n",
    "                sav.write(chunk)\n",
    "        print(f\"download number: {counter}\")\n",
    "                \n",
    "                \n",
    "def convert_pdf_to_csv(pdf_directory, csv_directory):\n",
    "    directory = fr'{pdf_directory}'\n",
    "    directory_output = fr'{csv_directory}'\n",
    "    count = 0\n",
    "    for file in os.listdir(directory):        \n",
    "        if file.endswith(\".pdf\"):\n",
    "            count = count + 1 \n",
    "            print(f'{directory}{file}: Conversion {count}')\n",
    "            tabula.convert_into(f'{directory}{file}', f'{directory_output}{count}.csv', output_format=\"csv\", pages='all')\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-coaching",
   "metadata": {},
   "source": [
    "## Functions Using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define important paths\n",
    "executable_path = \"/chromedriver\"\n",
    "download_path = f\"test\"\n",
    "\n",
    "# Define Routes (usually in xpaths)\n",
    "\n",
    "def browser_instance(executable_path, headless, download_path):\n",
    "    \n",
    "    \n",
    "    chrome_options =  Options()\n",
    "    if headless:\n",
    "        chrome_options.add_argument(\"--headless\")   \n",
    "    chrome_options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": download_path})    \n",
    "    driver = webdriver.Chrome(executable_path=executable_path, options = chrome_options)\n",
    "    return driver  \n",
    "\n",
    "def signIn(driver, url, signin_field, username_field, password_field):  \n",
    "    driver.get(url)\n",
    "    sign_in = driver.find_element_by_xpath(signin_field)\n",
    "    sign_in.click()\n",
    "    email_field = driver.find_element_by_xpath(username_field)\n",
    "    password_field = driver.find_element_by_xpath(password_field)\n",
    "    email_field.send_keys(USERNAME)\n",
    "    password_field.send_keys(PASSWORD + Keys.RETURN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    " driver = webdriver.Chrome(\"/Users/aadittambe/Documents/UMD/code_practice/news_app/test-stuff/chromedriver\")\n",
    "# driver.get(\"https://cpj.org/data/killed/?status=Killed&motiveConfirmed%5B%5D=Confirmed&type%5B%5D=Journalist&cc_fips%5B%5D=BG&cc_fips%5B%5D=BT&cc_fips%5B%5D=IN&cc_fips%5B%5D=MV&cc_fips%5B%5D=NP&cc_fips%5B%5D=PK&cc_fips%5B%5D=CE&start_year=1992&end_year=2021&group_by=year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getter():\n",
    "    counter = 0\n",
    "    results = []\n",
    "    driver.get(\"https://cpj.org/data/killed/?status=Killed&motiveConfirmed%5B%5D=Confirmed&type%5B%5D=Journalist&cc_fips%5B%5D=BG&cc_fips%5B%5D=BT&cc_fips%5B%5D=IN&cc_fips%5B%5D=MV&cc_fips%5B%5D=NP&cc_fips%5B%5D=PK&cc_fips%5B%5D=CE&start_year=1992&end_year=2021&group_by=year\")\n",
    "    while counter < 1:\n",
    "        next_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div/div[2]/div/div[1]/div/nav/ul/li[8]/a')))\n",
    "        table_finder = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div/div[2]/div/div[1]/div/table/tbody')))\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # print(soup.prettify())\n",
    "        table = soup.find(class_=\"table\")\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:\n",
    "          cells = row.find_all('td')\n",
    "          results.append([cell.text for cell in cells])\n",
    "    #       print(results)\n",
    "        \n",
    "        next_button.click()\n",
    "        print('debug')\n",
    "        counter = counter + 1\n",
    "        print(counter)\n",
    "#         return(results)\n",
    "\n",
    "\n",
    "        with open('results.csv','w') as output_file:\n",
    "            csvfile = csv.writer(output_file)\n",
    "            csvfile.writerow(['name', 'organization','date', 'location', 'death','type','na'])\n",
    "            csvfile.writerows(results)\n",
    "getter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change\n",
    "journalists_raw = pd.read_csv('journalists_killed.csv')\n",
    "journalists_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-probability",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Pakistani airstrike hit the lockup where Shaheen was beingheld by a local Taliban group in the Swat Valley, according to local newsreports citing a Taliban spokesman. The spokesman, Muslim Khan, said Shaheenwas among at least 25 people killed in the strike, according to the Daily Timesnewspaper. The precise location of the Taliban hideout was not reported.\n",
      "--\n",
      "Abdul Hakim Shimul, a reporter for the Bangladeshi national daily Samakal newspaper, died on February 3, 2017, from gunshot wounds sustained while covering political unrest in the northern Bangladeshi city of Shahjadpur the previous day. He was 42.\n",
      "--\n",
      "Unidentified assailants shot Haq as he was leaving the KhuzdarPress Club in the city of Khuzdar in Baluchistan province. Haq was thesecretary-general of the press club and a longtime local correspondent for ARYTelevision. ARY Television said it was not aware of any threats directedat Haq. But Hamid Mir, a prominent Pakistani journalist, wrote after Haq’sdeath that the journalist had been threatened by the Baluch Musalah Diffa Army(BMDA, or the Armed Baluch Defense) in November 2011 and had subsequently beennamed on a hit list issued by a BMDA spokesman.\n",
      "--\n",
      "Armed men shot Hajizai, a headmaster of a middle school whoalso worked at WASH TV, a private Baluchi-language TV channel, according tolocal news reports. The journalist was taken to a hospital, where he died, thereports said.\n",
      "--\n",
      "Six armed men dragged reporter Johra from his home in theMianwali district of Punjab and shot him, according to the Pakistan FederalUnion of Journalists. The attack came a day after his report on local drugtrafficking was aired nationally. Colleagues said Johra, 45, who had done earlier reports onthe drug trade, had received threats telling him to stop covering the issue.\n",
      "--\n",
      "Abdul Wahab, a reporter for Express News, and Pervez Khan, aWaqt TV journalist, were among 50 people killed in a double-suicide bomb attackin the Mohmand tribal district, according to international news reports. The journalists were covering a meeting of tribal leadersand government officials in Ghalanai, the administrative center of the region,when two suicide bombers wearing police uniforms detonated explosives. Newsreports said the meeting was called to discuss the formation of an anti-Talibanmilitia. Agence France-Presse said a Pakistani Taliban group took credit forthe attack, which injured more than 100 people.\n",
      "--\n",
      "Video journalist Achyutananda Sahu, who worked for the government-run broadcaster Doordarshan, was killed in Chhattisgarh on October 30, 2018, during a firefight between police and a Maoist militant group, according to news reports.\n",
      "--\n",
      "Haider, a blogger also known as “Thaba Baba,” was killed by assailants wielding machetes outside his home in the Pallabi neighborhood in the capital, Dhaka.\n",
      "--\n",
      "Ahmed Rilwan Abdulla, a blogger and reporter for independent news website Minivan News, was killed by a local Al-Qaeda affiliate in the Maldives on August 8, 2014, Husnu Al Suood, the head of the presidential commission on enforced disappearances and murders, said on September 1, 2019, according to Al-Jazeera. Rilwan was last seen on August 7, 2014, according to news reports and CPJ reporting, and had been considered missing for five years. Rilwan was forced into a car outside of his home at knifepoint in the early hours of August 8, 2014, according to the same reports. Al Suuod said he was then taken to a boat out at sea, where he was killed, according to Al-Jazeera. Al Suood said that Rilwan had been killed for his writing about alleged Al-Qaeda links in the Maldives and his advocacy for freedom of expression, according to news reports.\n",
      "--\n",
      "Nadesan, a veteran Tamil journalist with the national Tamil-languagedaily Virakesari, was shot by unidentified assailants in Batticaloa,a town on the eastern coast of Sri Lanka about 135 miles (216 kilometers)from the capital, Colombo, according to international news reportsand local journalists.\n",
      "--\n",
      "Gunmen in South Waziristan fatally shot Allah Noor, ajournalist for Peshawar-based Khyber TV, and Amir Nowab, a freelance cameramanfor Associated Press Television News and a reporter for the Frontier Postnewspaper. The journalists were riding with colleagues in a bus transportingthem from the town of Sararogha, where they had covered the surrender of asuspected tribal militant, Baitullah Mehsud.\n",
      "--\n",
      "Faktoo, an anchor for the state-owned Doordarshan television station in Srinagar, Kashmir, was assassinated, reportedly by militant separatists, who fired two shots at the journalist with a gun equipped with a silencer. He had received repeated threats from militant separatists because of his work and had been kidnapped and detained by a militant group in 1994.\n",
      "--\n",
      "Gunmen in South Waziristan fatally shot Allah Noor, ajournalist for Peshawar-based Khyber TV, and Amir Nowab, a freelance cameramanfor Associated Press Television News and a reporter for the Frontier Postnewspaper. The journalists were riding with colleagues in a bus transportingthem from the town of Sararogha, where they had covered the surrender of asuspected tribal militant, Baitullah Mehsud.\n",
      "--\n",
      "Four unidentified assailants wielding cleavers and machetes hacked Ananta Bijoy Das to death on a busy street as the blogger was heading to work in the city of Sylhet, according to news reports. Kamrul Hasan, commissioner of Sylhet police, told local journalists that the four assailants fled the scene.\n",
      "--\n",
      "Unidentified gunmen shot dead Mazumdar, the editor of an Assamese language daily Aji, as he was returning from his office outside his home in Rajgarh. His driver, Ramen Nath, and neighbors rushed him to a hospital, where Mazumdar was declared dead, according to the Telegraph.\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# don't change\n",
    "# def get_desc():\n",
    "my_list = []\n",
    "# providing url\n",
    "end = 10\n",
    "start = 1\n",
    "names_list = []\n",
    "url_list = []\n",
    "desc_list = []\n",
    "base_url = \"https://cpj.org/data/people/\"\n",
    "for index, row in journalists_raw.iterrows():\n",
    "    names_list.append(row[\"fullName\"])\n",
    "for name in names_list:\n",
    "    name = name.replace(' ', '-')\n",
    "    name_w_url = base_url + name\n",
    "    url_list.append(name_w_url)\n",
    "for link in url_list:\n",
    "    url = link\n",
    "    # opening the url for reading\n",
    "    html = urllib.request.urlopen(url)\n",
    "\n",
    "    # parsing the html file\n",
    "    htmlParse = BeautifulSoup(html, 'html.parser')\n",
    "    for para in htmlParse.find_all('article', {\"class\":\"entry-content\"}):\n",
    "        para = para.text\n",
    "        para = para.replace('Share this:TwitterFacebookWhatsAppLinkedInEmailTelegram ', '')\n",
    "        para = para.strip()\n",
    "        para = para.replace('.\\n', '.<br>')\n",
    "        para = para.split('<br>')\n",
    "        para = para[0]\n",
    "        para = para.replace('\\n','')\n",
    "        print((para))\n",
    "        print('--')\n",
    "#         print(para)\n",
    "#         print('--')\n",
    "    desc_text = para\n",
    "    desc_list.append(desc_text)\n",
    "journalists_with_desc = journalists_raw\n",
    "journalists_with_desc['desc'] = desc_list\n",
    "journalists_with_desc\n",
    "# get_desc()x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a step to just make sure\n",
    "journalists_with_desc.to_csv('journalists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# journalists with desc and location, country\n",
    "\n",
    "journalists_city_country = journalists_with_desc\n",
    "journalists_city_country[\"city_country\"] = journalists_city_country[\"location\"] + \", \"+ journalists_city_country[\"country\"]\n",
    "\n",
    "journalists_city_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean that column using string detect\n",
    "journalists_city_country_clean = journalists_city_country\n",
    "journalists_city_country_clean['city_country'] = journalists_city_country_clean['city_country'].str.replace('an area outside ','')\n",
    "journalists_city_country_clean['city_country'] = journalists_city_country_clean['city_country'].str.replace('an area near ','')\n",
    "journalists_city_country_clean['city_country'] = journalists_city_country_clean['city_country'].str.replace('Malé','Male')\n",
    "\n",
    "\n",
    "# journalists_city_country_clean.sort_values(by = [\"city_country\"], ascending=True)\n",
    "journalists_city_country_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "jourcoords = journalists_city_country_clean #.to_csv(\"clean_journalists_deaths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "jourcoords = journalists_city_country_clean\n",
    "jourcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_list = []\n",
    "for place in jourcoords[\"city_country\"]:\n",
    "    place_list.append(place)\n",
    "    \n",
    "lat_list = []\n",
    "long_list = []\n",
    "for item in place_list:\n",
    "#     while True:\n",
    "    try: \n",
    "        geolocator = Nominatim(user_agent=\"Aadit\")\n",
    "        location = geolocator.geocode(item)\n",
    "        lat_list.append(location.latitude)\n",
    "        long_list.append(location.longitude)\n",
    "    except (RuntimeError, TypeError, NameError, AttributeError):\n",
    "        lat_list.append('pass')\n",
    "        long_list.append('pass')\n",
    "\n",
    "print(len(long_list))\n",
    "print(len(lat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jourcoords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "jourcoords[\"lat\"] = lat_list\n",
    "jourcoords['lon'] = long_list\n",
    "jourcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "jourcoords.to_csv('final_file_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the descs\n",
    "file = pd.read_csv('final_file.csv')\n",
    "file[\"desc_clean\"] = file[\"desc\"].str.replace('\\n','')\n",
    "file[\"desc_clean\"] = file[\"desc_clean\"].str.replace('Share this:TwitterFacebookWhatsAppLinkedInEmailTelegram','')\n",
    "file\n",
    "\n",
    "file.to_csv('final_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-scale",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "\n",
    "my_list = []\n",
    "# providing url\n",
    "end = 10\n",
    "start = 1\n",
    "\n",
    "url = \"https://cpj.org/data/people/abadullah-hananzai/\"\n",
    "\n",
    "# opening the url for reading\n",
    "html = urllib.request.urlopen(url)\n",
    "\n",
    "# parsing the html file\n",
    "htmlParse = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# getting all the paragraphs\n",
    "for para in htmlParse.find_all(\"p\"):\n",
    "    para = para.get_text()\n",
    "#     print(para)\n",
    "    x = para.replace('Our EIN is 13-3081500.', '')\n",
    "    x = x.replace('Committee to Protect Journalists', '')\n",
    "    x = x.replace('P.O. Box 2675', '')\n",
    "    x = x.replace('New York, NY 10108', '')\n",
    "    x = x.replace('Tel 212-465-1004', '')\n",
    "    x = x.replace('Fax 212-465-9568', '')\n",
    "    x = x.replace('Except where noted, text on this website is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.', '')\n",
    "    x = x.replace('Images and other media are not covered by the Creative Commons license. For more information about permissions, see our FAQs.', '')\n",
    "    x = x.replace('info@cpj.org', '')\n",
    "    x = x.replace('CPJ is a 501(c)3 non-profit.', '')\n",
    "    x = x.rstrip(\"\\t\")\n",
    "#     print(x)\n",
    "    y = x.split('\\n')\n",
    "    for graf in y:\n",
    "        my_list.append(graf)\n",
    "# print(my_list[0])\n",
    "res = my_list[: len(my_list) - 17]\n",
    "# print(res)\n",
    "popped_element = res.pop(0)\n",
    "# print(res)\n",
    "final_desc_clean = '<br> '.join(res)\n",
    "final_desc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"test\"] = x[\"desc_clean\"].str.strip()\n",
    "\n",
    "# x[\"test\"] = x[\"test\"].str.replace('\\n','')\n",
    "for i in x[\"test\"]:\n",
    "    print(i)\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "specified-corporation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Pakistani airstrike hit the lockup where Shaheen was beingheld by a local Taliban group in the Swat Valley, according to local newsreports citing a Taliban spokesman. The spokesman, Muslim Khan, said Shaheenwas among at least 25 people killed in the strike, according to the Daily Timesnewspaper. The precise location of the Taliban hideout was not reported.\n",
      "--\n",
      "Abdul Hakim Shimul, a reporter for the Bangladeshi national daily Samakal newspaper, died on February 3, 2017, from gunshot wounds sustained while covering political unrest in the northern Bangladeshi city of Shahjadpur the previous day. He was 42.\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# don't change\n",
    "# def get_desc():\n",
    "my_list = []\n",
    "# providing url\n",
    "end = 10\n",
    "start = 1\n",
    "names_list = []\n",
    "para_list = []\n",
    "url_list = [\"https://cpj.org/data/people/abdul-aziz-shaheen/\", \"https://cpj.org/data/people/abdul-hakim-shimul/\"]\n",
    "for link in url_list:\n",
    "    url = link\n",
    "    # opening the url for reading\n",
    "    html = urllib.request.urlopen(url)\n",
    "\n",
    "    # parsing the html file\n",
    "    htmlParse = BeautifulSoup(html, 'html.parser')\n",
    "    for para in htmlParse.find_all('article', {\"class\":\"entry-content\"}):\n",
    "        para = para.text\n",
    "        para = para.replace('Share this:TwitterFacebookWhatsAppLinkedInEmailTelegram ', '')\n",
    "        para = para.strip()\n",
    "        para = para.replace('.\\n', '.<br>')\n",
    "        para = para.split('<br>')\n",
    "        para = para[0]\n",
    "        para = para.replace('\\n','')\n",
    "        print((para))\n",
    "        print('--')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     p = htmlParse.find_all(\"p\")\n",
    "# #     p = p\n",
    "#     print(p.text)\n",
    "#     print('---')\n",
    "#     for para in htmlParse.find_all(\"p\"):\n",
    "#         para=para.get_text()\n",
    "#         print(para_list)\n",
    "#         para_list.append(para)\n",
    "#         print('---')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-greek",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-fellow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
